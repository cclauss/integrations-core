## WARNING
##
## This sample works only for Kafka >= 0.8.2.
## If you are running a version older than that, you can refer to agent 5.2.x released
## sample files, https://raw.githubusercontent.com/DataDog/dd-agent/5.2.1/conf.d/kafka.yaml.example

instances:

#  - host: localhost  # confluentinc/cp-zookeeper
#    port: 31000      # OK
  - host: localhost  # confluentinc/cp-server
    port: 31001      # OK
  - host: localhost  # cnfldemos/cp-server-connect-datagen
    port: 31002      # OK
##  - host: localhost  # confluentinc/cp-enterprise-control-center
##    port: 31003      # DOES NOT WORK
#  - host: localhost  # confluentinc/cp-ksql-server
#    port: 31004      # OK
##  - host: localhost  # confluentinc/ksql-examples
##    port: 31005      # DOES NOT WORK
  - host: localhost  # confluentinc/cp-kafka-rest
    port: 31006      # OK
  - host: localhost  # confluentinc/cp-schema-registry
    port: 31007      # OK
  - host: localhost  # confluentinc/cp-enterprise-replicator
    port: 31008      # OK

    ## @param host - string - required
    ## Kafka host to connect to.
    #
#  - host: localhost

    ## @param port - integer - required
    ## Kafka port to connect to.
    ## This is the JMX port on which Kafka exposes its metrics.
    #
#    port: 31000

    ## @param user - string - optional
    ## Username from the credentials needed to connect to the host.
    #
    # user: <USERNAME>

    ## @param password - string - optional
    ## Password from the credentials needed to connect to the host.
    #
    # password: <PASSWORD>

    ## @param process_name_regex - string - optional
    ## Instead of specifying a host, and port. The agent can connect using the attach api.
    ## This requires the JDK to be installed and the path to tools.jar to be set below in tools_jar_path parameter.
    #
    # process_name_regex: .*process_name.*

    ## @param tools_jar_path - string - optional
    ## Needs to be set when process_name_regex parameter is set.
    #
    # tools_jar_path: /usr/lib/jvm/java-7-openjdk-amd64/lib/tools.jar

    ## @param name - string - optional
    ## Set your instance name.
    #
    # name: kafka_instance

    ## @param java_bin_path - string - optional
    ## java_bin_path should be set if the agent cannot find your java executable
    #
    # java_bin_path: <JAVA_PATH>

    ## @param java_options - string - optional
    ## List of Java JVM options.
    #
    # java_options: "-Xmx200m -Xms50m"

    ## @param trust_store_path - string - optional
    ## trust_store_path should be set if ssl is enabled.
    ## path to your trusted store
    #
    # trust_store_path: <TRUSTSTORE.JKS_PATH>

    ## @param trust_store_password - string - optional
    ## trust_store_password should be set if ssl is enabled
    ## password for your TrustStore.jks file
    #
    # trust_store_password: <PASSWORD>

    ## @param key_store_path - string - optional
    ## key_store_path should be set if client authentication is enabled on the target JVM.
    ## path to your key store
    #
    # key_store_path: <KEYSTORE.JKS_PATH>

    ## @param key_store_password - string - optional
    ## key_store_password should be set if client authentication is enabled on the target JVM.
    ## password for your KeyStore.jks file
    #
    # key_store_password: <PASSWORD>

    ## @param rmi_registry_ssl - boolean - optional
    ## Whether or not the agent should connect to the rmi registry using ssl.
    #
    # rmi_registry_ssl: false

    ## @param tags - list of key:value element - optional
    ## List of tags to attach to every metric, event and service check emitted by this integration.
    ##
    ## Learn more about tagging: https://docs.datadoghq.com/tagging/
    #
    # tags:
    #   - <KEY_1>:<VALUE_1>
    #   - <KEY_2>:<VALUE_2>

## Log Section (Available for Agent >=6.0)
##
## type - mandatory - Type of log input source (tcp / udp / file / windows_event)
## port / path / channel_path - mandatory - Set port if type is tcp or udp. Set path if type is file. Set channel_path if type is windows_event
## service - mandatory - Name of the service that generated the log
## source  - mandatory - Attribute that defines which Integration sent the logs
## sourcecategory - optional - Multiple value attribute. Used to refine the source attribute
## tags: - optional - Add tags to the collected logs
##
## Discover Datadog log collection: https://docs.datadoghq.com/logs/log_collection/
#
# logs:
#
#   - type: file
#     path: /var/log/kafka/server.log
#     source: kafka
#     service: myservice
## To handle multi line that starts with yyyy-mm-dd use the following pattern
#     log_processing_rules:
#        - type: multi_line
#          name: start_with_date
#          pattern: \d{4}\-(0?[1-9]|1[012])\-(0?[1-9]|[12][0-9]|3[01])

init_config:

  ## @param is_jmx - boolean - required
  ## Whether or not this file is a configuration for a JMX integration
  #
  is_jmx: true

  ## @param collect_default_metrics - boolean - required
  ## Whether or not the check should collect all default metrics for this integration.
  #
  collect_default_metrics: true

  ## @param conf - list of objects - required
  ## List of metrics to be collected by the integration
  ## Read http://docs.datadoghq.com/integrations/java/ to learn how to customize it
  ## Agent 5: Customize all your metrics below
  ## Agent 6: The default metrics to be collected are kept in metrics.yaml, but you can still add your own metrics here
  conf:
  - include:
      # Uncomment when https://github.com/DataDog/jmxfetch/pull/277 is merged
      # class_regex: .*$Gauge
      domain_regex: kafka\..*
      bean:
        # Kafka Broker Metrics
        - kafka.controller:type=KafkaController,name=OfflinePartitionsCount
        - kafka.controller:type=KafkaController,name=ActiveControllerCount
        - kafka.server:type=ReplicaManager,name=UnderMinIsrPartitionCount
        - kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions
        - kafka.server:type=ReplicaManager,name=PartitionCount
        - kafka.server:type=ReplicaManager,name=LeaderCount
        - kafka.server:type=ReplicaFetcherManager,name=MaxLag,clientId=Replica
        - kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent
        - kafka.network:type=RequestChannel,name=RequestQueueSize
        - kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Produce
        - kafka.server:type=DelayedOperationPurgatory,name=PurgatorySize,delayedOperation=Fetch
      attribute:
        Value:
          alias: $domain.$type.$name
          metric_type: gauge

  - include:
      # Uncomment when https://github.com/DataDog/jmxfetch/pull/277 is merged
      # class_regex: .*$Gauge
      domain_regex: kafka\..*
      bean_regex:
        # Kafka Broker Metrics
        - kafka\.cluster:type=Partition,name=UnderMinIsr,.*
        - kafka\.server:type=FetcherLagMetrics,name=ConsumerLag,.*
      attribute:
        Value:
          alias: $domain.$type.$name
          metric_type: gauge

  - include:
      # Uncomment when https://github.com/DataDog/jmxfetch/pull/277 is merged
      # class_regex: .*$Meter
      domain_regex: kafka\..*
      bean:
        # Kafka Broker Metrics
        - kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec
        - kafka.server:type=BrokerTopicMetrics,name=BytesOutPerSec
        - kafka.server:type=BrokerTopicMetrics,name=TotalProduceRequestsPerSec
        - kafka.server:type=BrokerTopicMetrics,name=TotalFetchRequestsPerSec
        - kafka.server:type=BrokerTopicMetrics,name=FailedProduceRequestsPerSec
        - kafka.server:type=BrokerTopicMetrics,name=FailedFetchRequestsPerSec
        - kafka.controller:type=ControllerStats,name=UncleanLeaderElectionsPerSec
        - kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent
        - kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec
        - kafka.server:type=ReplicaManager,name=IsrShrinksPerSec
        - kafka.server:type=ReplicaManager,name=IsrExpandsPerSec
      attribute:
        Count:
          alias: $domain.$type.$name.rate
          metric_type: rate

  - include:
      # Uncomment when https://github.com/DataDog/jmxfetch/pull/277 is merged
      # class_regex: .*$Meter
      domain_regex: kafka\..*
      bean_regex:
        # Kafka Broker Metrics
        - kafka.network:type=RequestMetrics,name=RequestsPerSec,request=(Produce|FetchConsumer|FetchFollower).*
      attribute:
        Count:
          alias: $domain.$type.$name.rate
          metric_type: rate

  - include:
      # Uncomment when https://github.com/DataDog/jmxfetch/pull/277 is merged
      # class_regex: .*$Timer
      domain_regex: kafka\..*
      bean:
        # Kafka Broker Metrics
        - kafka.controller:type=ControllerStats,name=LeaderElectionRateAndTimeMs
        - kafka.log:type=LogFlushStats,name=LogFlushRateAndTimeMs
      attribute:
        Count:
          alias: $domain.$type.$name.rate
          metric_type: rate
        Mean:
          alias: $domain.$type.$name.avg
          metric_type: gauge

  - include:
      # Uncomment when https://github.com/DataDog/jmxfetch/pull/277 is merged
      # class_regex: .*$Histogram
      domain_regex: kafka\..*
      bean_regex:
        # Kafka Broker Metrics
        - kafka\.network:type=RequestMetrics,name=TotalTimeMs,request=(Produce|FetchConsumer|FetchFollower).*
        - kafka\.network:type=RequestMetrics,name=RequestQueueTimeMs,request=(Produce|FetchConsumer|FetchFollower).*
        - kafka\.network:type=RequestMetrics,name=LocalTimeMs,request=(Produce|FetchConsumer|FetchFollower).*
        - kafka\.network:type=RequestMetrics,name=RemoteTimeMs,request=(Produce|FetchConsumer|FetchFollower).*
        - kafka\.network:type=RequestMetrics,name=ResponseQueueTimeMs,request=(Produce|FetchConsumer|FetchFollower).*
        - kafka\.network:type=RequestMetrics,name=ResponseSendTimeMs,request=(Produce|FetchConsumer|FetchFollower).*
      attribute:
        Count:
          alias: $domain.$type.$name.rate
          metric_type: rate
        Mean:
          alias: $domain.$type.$name.avg
          metric_type: gauge

  # Kafka Connect Metrics
  # https://kafka.apache.org/documentation/#connect_monitoring
  - include:
      domain: kafka.connect
      bean: kafka.connect:type=connect-worker-metrics
      attribute:
        connector-count:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-startup-attempts-total:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-startup-failure-percentage:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-startup-failure-total:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-startup-success-percentage:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-startup-success-total:
          alias: $domain.$type.$attribute
          metric_type: gauge
        task-count:
          alias: $domain.$type.$attribute
          metric_type: gauge
        task-startup-attempts-total:
          alias: $domain.$type.$attribute
          metric_type: gauge
        task-startup-failure-percentage:
          alias: $domain.$type.$attribute
          metric_type: gauge
        task-startup-failure-total:
          alias: $domain.$type.$attribute
          metric_type: gauge
        task-startup-success-percentage:
          alias: $domain.$type.$attribute
          metric_type: gauge
        task-startup-success-total:
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Kafka Connect Metrics
  # https://kafka.apache.org/documentation/#connect_monitoring
  - include:
      domain: kafka.connect
      # Recent metrics merged on 3 Oct 2019: https://github.com/apache/kafka/pull/6843
      # Probably not present in the connector we are using for testing
      bean_regex: kafka\.connect:type=connect-worker-metrics,connector=.*
      attribute:
        connector-destroyed-task-count:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-failed-task-count:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-paused-task-count:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-running-task-count:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-total-task-count:
          alias: $domain.$type.$attribute
          metric_type: gauge
        connector-unassigned-task-count:
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Kafka Connect Metrics
  # https://kafka.apache.org/documentation/#connect_monitoring
  - include:
      domain: kafka.connect
      bean: kafka.connect:type=connect-worker-rebalance-metrics
      attribute:
        completed-rebalances-total:
          alias: $domain.$type.$attribute
          metric_type: gauge
        epoch:
          alias: $domain.$type.$attribute
          metric_type: gauge
        rebalance-avg-time-ms:
          alias: $domain.$type.$attribute
          metric_type: gauge
        rebalance-max-time-ms:
          alias: $domain.$type.$attribute
          metric_type: gauge
        rebalancing:
          alias: $domain.$type.$attribute
          metric_type: gauge
        time-since-last-rebalance-ms:
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Kafka Connect Metrics
  # https://kafka.apache.org/documentation/#connect_monitoring
  - include:
      domain: kafka.connect
      bean_regex: kafka\.connect:type=connector-task-metrics,connector=.*,task=.*
      attribute:
        batch-size-avg:
          # The average size of the batches processed by the connector.
          alias: $domain.$type.$attribute
          metric_type: gauge
        batch-size-max:
          # The maximum size of the batches processed by the connector.
          alias: $domain.$type.$attribute
          metric_type: gauge
        offset-commit-avg-time-ms:
          # The average time in milliseconds taken by this task to commit offsets.
          alias: $domain.$type.$attribute
          metric_type: gauge
        offset-commit-failure-percentage:
          # The average percentage of this task's offset commit attempts that failed.
          alias: $domain.$type.$attribute
          metric_type: gauge
        offset-commit-max-time-ms:
          # The maximum time in milliseconds taken by this task to commit offsets.
          alias: $domain.$type.$attribute
          metric_type: gauge
        offset-commit-success-percentage:
          # The average percentage of this task's offset commit attempts that succeeded.
          alias: $domain.$type.$attribute
          metric_type: gauge
        pause-ratio:
          # The fraction of time this task has spent in the pause state.
          alias: $domain.$type.$attribute
          metric_type: gauge
        running-ratio:
          # The fraction of time this task has spent in the running state.
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Kafka Connect Metrics
  # https://kafka.apache.org/documentation/#connect_monitoring
  - include:
      domain: kafka.connect
      bean_regex: kafka\.connect:type=sink-task-metrics,connector=.*,task=.*
      attribute:
        offset-commit-completion-rate:
          # The average per-second number of offset commit completions that were completed successfully.
          alias: $domain.$type.$attribute
          metric_type: gauge
        offset-commit-completion-total:
          # The total number of offset commit completions that were completed successfully.
          alias: $domain.$type.$attribute
          metric_type: gauge
        offset-commit-seq-no:
          # The current sequence number for offset commits.
          alias: $domain.$type.$attribute
          metric_type: gauge
        offset-commit-skip-rate:
          # The average per-second number of offset commit completions that were received too late and skipped/ignored.
          alias: $domain.$type.$attribute
          metric_type: gauge
        offset-commit-skip-total:
          # The total number of offset commit completions that were received too late and skipped/ignored.
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition-count:
          # The number of topic partitions assigned to this task belonging to the named sink connector in this worker.
          alias: $domain.$type.$attribute
          metric_type: gauge
        put-batch-avg-time-ms:
          # The average time taken by this task to put a batch of sinks records.
          alias: $domain.$type.$attribute
          metric_type: gauge
        put-batch-max-time-ms:
          # The maximum time taken by this task to put a batch of sinks records.
          alias: $domain.$type.$attribute
          metric_type: gauge
        sink-record-active-count:
          # The number of records that have been read from Kafka but not yet completely committed/flushed/acknowledged by the sink task.
          alias: $domain.$type.$attribute
          metric_type: gauge
        sink-record-active-count-avg:
          # The average number of records that have been read from Kafka but not yet completely committed/flushed/acknowledged by the sink task.
          alias: $domain.$type.$attribute
          metric_type: gauge
        sink-record-active-count-max:
          # The maximum number of records that have been read from Kafka but not yet completely committed/flushed/acknowledged by the sink task.
          alias: $domain.$type.$attribute
          metric_type: gauge
        sink-record-lag-max:
          # The maximum lag in terms of number of records that the sink task is behind the consumer's position for any topic partitions.
          alias: $domain.$type.$attribute
          metric_type: gauge
        sink-record-read-rate:
          # The average per-second number of records read from Kafka for this task belonging to the named sink connector in this worker. This is before transformations are applied.
          alias: $domain.$type.$attribute
          metric_type: gauge
        sink-record-read-total:
          # The total number of records read from Kafka by this task belonging to the named sink connector in this worker, since the task was last restarted.
          alias: $domain.$type.$attribute
          metric_type: gauge
        sink-record-send-rate:
          # The average per-second number of records output from the transformations and sent/put to this task belonging to the named sink connector in this worker. This is after transformations are applied and excludes any records filtered out by the transformations.
          alias: $domain.$type.$attribute
          metric_type: gauge
        sink-record-send-total:
          # The total number of records output from the transformations and sent/put to this task belonging to the named sink connector in this worker, since the task was last restarted.
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Kafka Connect Metrics
  # https://kafka.apache.org/documentation/#connect_monitoring
  - include:
      domain: kafka.connect
      bean_regex: kafka\.connect:type=source-task-metrics,connector=.*,task=.*
      attribute:
        poll-batch-avg-time-ms:
          # The average time in milliseconds taken by this task to poll for a batch of source records.
          alias: $domain.$type.$attribute
          metric_type: gauge
        poll-batch-max-time-ms:
          # The maximum time in milliseconds taken by this task to poll for a batch of source records.
          alias: $domain.$type.$attribute
          metric_type: gauge
        source-record-active-count:
          # The number of records that have been produced by this task but not yet completely written to Kafka.
          alias: $domain.$type.$attribute
          metric_type: gauge
        source-record-active-count-avg:
          # The average number of records that have been produced by this task but not yet completely written to Kafka.
          alias: $domain.$type.$attribute
          metric_type: gauge
        source-record-active-count-max:
          # The maximum number of records that have been produced by this task but not yet completely written to Kafka.
          alias: $domain.$type.$attribute
          metric_type: gauge
        source-record-poll-rate:
          # The average per-second number of records produced/polled (before transformation) by this task belonging to the named source connector in this worker.
          alias: $domain.$type.$attribute
          metric_type: gauge
        source-record-poll-total:
          # The total number of records produced/polled (before transformation) by this task belonging to the named source connector in this worker.
          alias: $domain.$type.$attribute
          metric_type: gauge
        source-record-write-rate:
          # The average per-second number of records output from the transformations and written to Kafka for this task belonging to the named source connector in this worker. This is after transformations are applied and excludes any records filtered out by the transformations.
          alias: $domain.$type.$attribute
          metric_type: gauge
        source-record-write-total:
          # The number of records output from the transformations and written to Kafka for this task belonging to the named source connector in this worker, since the task was last restarted.
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Kafka Connect Metrics
  # https://kafka.apache.org/documentation/#connect_monitoring
  - include:
      domain: kafka.connect
      bean_regex: kafka\.connect:type=task-error-metrics,connector=.*,task=.*
      attribute:
        deadletterqueue-produce-failures:
          # The number of failed writes to the dead letter queue.
          alias: $domain.$type.$attribute
          metric_type: gauge
        deadletterqueue-produce-requests:
          # The number of attempted writes to the dead letter queue.
          alias: $domain.$type.$attribute
          metric_type: gauge
        last-error-timestamp:
          # The epoch timestamp when this task last encountered an error.
          alias: $domain.$type.$attribute
          metric_type: gauge
        total-errors-logged:
          # The number of errors that were logged.
          alias: $domain.$type.$attribute
          metric_type: gauge
        total-record-errors:
          # The number of record processing errors in this task.
          alias: $domain.$type.$attribute
          metric_type: gauge
        total-record-failures:
          # The number of record processing failures in this task.
          alias: $domain.$type.$attribute
          metric_type: gauge
        total-records-skipped:
          # The number of records skipped due to errors.
          alias: $domain.$type.$attribute
          metric_type: gauge
        total-retries:
          # The number of operations retried.
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Components Metrics:
  #   - Kafka REST: https://docs.confluent.io/current/kafka-rest/monitoring.html
  #   - Kafka Schema Registry: https://docs.confluent.io/current/schema-registry/monitoring.html
  - include:
      domain_regex: kafka\.(rest|schema\.registry)
      bean_regex: kafka\.(rest|schema\.registry):type=jetty-metrics
      attribute:
        connections-active:
          # Total number of active TCP connections.
          alias: $domain.$type.$attribute
          metric_type: gauge
        connections-opened-rate:
          # The average rate per second of opened TCP connections.
          alias: $domain.$type.$attribute
          metric_type: gauge
        connections-closed-rate:
          # The average rate per second of closed TCP connections.
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Components Metrics:
  #   - Kafka REST: https://docs.confluent.io/current/kafka-rest/monitoring.html
  #   - Kafka Schema Registry: https://docs.confluent.io/current/schema-registry/monitoring.html
  - include:
      domain_regex: kafka\.(rest|schema\.registry)
      bean_regex: kafka\.(rest|schema\.registry):type=jetty-metrics
      attribute:
        brokers.list.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.assign+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.assignment+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.commit-offsets+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.commit.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.committed-offsets+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.create+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.create.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.delete+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.delete.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.records.read-avro+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.records.read-binary+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.records.read-json+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.seek-to-beginning+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.seek-to-end+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.seek-to-offset+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.subscribe+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.subscription+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.topic.read-avro.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.topic.read-binary.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.topic.read-json.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        consumer.unsubscribe+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.consume-avro.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.consume-binary.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.consume-json.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.get+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.get.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.produce-avro+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.produce-avro.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.produce-binary+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.produce-binary.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.produce-json+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partition.produce-json.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partitions.list+v2.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        partitions.list.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        root.get.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        root.post.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        topic.get.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        topic.produce-avro.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        topic.produce-binary.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        topic.produce-json.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge
        topics.list.request-error-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Components Metrics:
  #   - Kafka Schema Registry: https://docs.confluent.io/current/schema-registry/monitoring.html
  - include:
      domain: kafka.schema.registry
      bean: kafka.schema.registry:type=master-slave-role
      attribute:
        master-slave-role:
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Components Metrics:
  #   - Confluent Replicator: https://docs.confluent.io/current/multi-dc-deployments/replicator/replicator-monitoring.html
  - include:
      domain: confluent.replicator
      bean_regex: confluent\.replicator:type=confluent-replicator-task-metrics,confluent-replicator-task=.*,confluent-replicator-task-topic-partition=.*
      attribute:
        confluent-replicator-task-topic-partition-message-lag:
          # The number of messages that were produced to the origin cluster, but have not yet arrived to the destination cluster.
          alias: $domain.$type.$attribute
          metric_type: gauge
        confluent-replicator-task-topic-partition-throughput:
          # The number of messages replicated per second from the source to destination cluster.
          alias: $domain.$type.$attribute
          metric_type: gauge
        confluent-replicator-task-topic-partition-latency:
          # The average time between message production to the source cluster and message production to the destination cluster.
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Components Metrics:
  #   - Confluent Replicator Important Producer Metrics: https://docs.confluent.io/current/multi-dc-deployments/replicator/replicator-monitoring.html#important-producer-metrics
  - include:
      domain: kafka.producer
      bean_regex: kafka\.producer:type=producer-metrics,client-id=.*
      attribute:
        # batch-size-avg and batch-size-max:
        # If they are consistently close to the configured batch.size, you may be producing as fast as possible and you’ll want to increase the batch size to get better batching.
        batch-size-avg:
          # The average number of bytes sent per partition per-request.
          alias: $domain.$type.$attribute
          metric_type: gauge
        batch-size-max:
          # The max number of bytes sent per partition per-request.
          alias: $domain.$type.$attribute
          metric_type: gauge

        # io-ratio or io-wait-ratio:
        # If the io-ratio is low or io-wait-ratio is high, this means the producer is not very busy and is unlikely to be a bottleneck.
        io-ratio:
          # The fraction of time the I/O thread spent doing I/O
          alias: $domain.$type.$attribute
          metric_type: gauge
        io-wait-ratio:
          # The fraction of time the I/O thread spent waiting
          alias: $domain.$type.$attribute
          metric_type: gauge

        # outgoing-byte-rate:
        # Reports the producer throughput when writing to destination Kafka.
        outgoing-byte-rate:
          # The number of outgoing bytes sent to all servers per second
          alias: $domain.$type.$attribute
          metric_type: gauge

        # record-retry-rate and record-error-rate:
        # The average per-second number of retried record sends and failed record sends for a topic. High number of those can indicate issues writing to the destination cluster.
        record-retry-rate:
          # The average per-second number of retried record sends
          alias: $domain.$type.$attribute
          metric_type: gauge
        record-error-rate:
          # The average per-second number of record sends that resulted in errors
          alias: $domain.$type.$attribute
          metric_type: gauge

        # produce-throttle-time-avg and produce-throttle-time-max:
        # Produce requests may be throttled to meet quotas configured on the destination cluster. If these are non-zero, it indicates that the destination brokers are slowing the producer down and the quotas configuration should be reviewed. For more information on quotas see Enforcing Client Quotas.
        produce-throttle-time-avg:
          # The average time in ms a request was throttled by a broker
          alias: $domain.$type.$attribute
          metric_type: gauge
        produce-throttle-time-max:
          # The maximum time in ms a request was throttled by a broker
          alias: $domain.$type.$attribute
          metric_type: gauge

        # waiting-threads and bufferpool-wait-time:
        # Non-zero values here indicate memory pressure. Connect producers can’t send events fast enough, resulting in full memory buffers that cause Replicator threads to block.
        waiting-threads:
          # The number of user threads blocked waiting for buffer memory to enqueue their records
          alias: $domain.$type.$attribute
          metric_type: gauge
        bufferpool-wait-time-total:
          # The total time an appender waits for space allocation.
          alias: $domain.$type.$attribute
          metric_type: gauge

  # Components Metrics:
  #   - Confluent Replicator Important Consumer Metrics: https://docs.confluent.io/current/multi-dc-deployments/replicator/replicator-monitoring.html#important-producer-metrics
  # Note about `*-total` metrics:
  #   Since we already have `*-rate`, we can use `gauge` type for `*-total` metrics to avoid losing data (using `rate` or `monotonic_count` will only give us the delta).
  - include:
      domain: kafka.consumer
      bean_regex: kafka\.consumer:type=consumer-metrics,client-id=.*
      attribute:
        # io-ratio or io-wait-ratio:
        # If the io-ratio is low or io-wait-ratio is high, this means the consumer is not very busy and is unlikely to be a bottleneck.
        io-ratio:
          # The fraction of time the I/O thread spent doing I/O
          alias: $domain.$type.$attribute
          metric_type: gauge
        io-wait-ratio:
          # The fraction of time the I/O thread spent waiting
          alias: $domain.$type.$attribute
          metric_type: gauge

        # bytes-consumed-rate:
        # Indicates throughput of Replicator reading events from origin cluster.
        bytes-consumed-rate:
          # Indicates throughput of Replicator reading events from origin cluster.
          alias: $domain.$type.$attribute
          metric_type: gauge

        # fetch-size-avg and fetch-size-max:
        # If they are close to the configured maximum fetch size consistently, it means that Replicator is reading at the maximum possible rate. Increase the maximum fetch size and check if the throughput per task is improved.
        fetch-size-avg:
          alias: $domain.$type.$attribute
          metric_type: gauge
        fetch-size-max:
          alias: $domain.$type.$attribute
          metric_type: gauge

        # records-lag-max:
        # The maximum lag in terms of number of records for any partition. An increasing value over time indicates that Replicator is not keeping up with the rate at which events are written to the origin cluster.
        records-lag-max:
          # The maximum lag in terms of number of records for any partition. An increasing value over time indicates that Replicator is not keeping up with the rate at which events are written to the origin cluster.
          alias: $domain.$type.$attribute
          metric_type: gauge

        # fetch-rate, fetch-size-avg and fetch-size-max:
        # If fetch-rate is high but fetch-size-avg and fetch-size-max are not close to the maximum configured fetch size, perhaps the consumer is “churning”. Try increasing the fetch.min.bytes and fetch.max.wait configuration. This can help the consumer batch more efficiently.
        fetch-rate:
          alias: $domain.$type.$attribute
          metric_type: gauge

        # fetch-throttle-time-max and fetch-throttle-time-avg:
        # Fetch requests may be throttled to meet quotas configured on the origin cluster. If these are non-zero, it indicates that the origin brokers are slowing the consumer down and the quotas configuration should be reviewed. For more information on quotas see Enforcing Client Quotas
        fetch-throttle-time-max:
          # Fetch requests may be throttled to meet quotas configured on the origin cluster. If these are non-zero, it indicates that the origin brokers are slowing the consumer down and the quotas configuration should be reviewed. For more information on quotas see Enforcing Client Quotas
          alias: $domain.$type.$attribute
          metric_type: gauge
        fetch-throttle-time-avg:
          # Fetch requests may be throttled to meet quotas configured on the origin cluster. If these are non-zero, it indicates that the origin brokers are slowing the consumer down and the quotas configuration should be reviewed. For more information on quotas see Enforcing Client Quotas
          alias: $domain.$type.$attribute
          metric_type: gauge

        # metrics not listed in official doc, but might be useful to collect
        connection-count:
          # The current number of active connections.
          alias: $domain.$type.$attribute
          metric_type: gauge
        network-io-rate:
          # The number of network operations (reads or writes) on all connections per second
          alias: $domain.$type.$attribute
          metric_type: gauge
        request-rate:
          # The number of requests sent per second
          alias: $domain.$type.$attribute
          metric_type: gauge

#- Replicator
#    - Confluent Replicator is a Kafka Connect-based tool for replicating data between Kafka clusters in different data centers.
#    - [Documentation](https://docs.confluent.io/current/connect/kafka-connect-replicator/index.html)
#    - [Metrics](https://docs.confluent.io/current/multi-dc-deployments/replicator/replicator-monitoring.html) (6 metrics + 12 metrics subset of producer/consumer)

#
#- KSQL
#    - An event streaming database.
#    - [Documentation](https://www.confluent.io/product/ksql/)
#    - [Metrics](https://docs.confluent.io/current/ksql/docs/installation/server-config/index.html#jmx-metrics) (11 metrics)
#- Kafka Streams applications
#    - Kafka Streams is a client library for building applications where the input and output are stored in clusters.
#    - [Documentation](https://docs.confluent.io/current/tutorials/cp-demo/docs/index.html)
#    - [Metrics](https://docs.confluent.io/current/streams/monitoring.html#built-in-metrics) (93 metrics)

#- RBAC and LDAP Health Metrics
#    - [Metrics](https://docs.confluent.io/current/kafka/monitoring.html#rbac-and-ldap-health-metrics) (8 metrics)
#
